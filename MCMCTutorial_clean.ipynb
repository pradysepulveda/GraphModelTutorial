{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical models in Python : basics tutorial\n",
    "\n",
    "## BdM lab\n",
    "### June 2021\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import theano as theano\n",
    "import arviz as az\n",
    "# --------------------\n",
    "# extras for analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model  # packages for the logistic regression function to plot the logistic regression \n",
    "from sklearn.linear_model import LogisticRegression # \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score1(data_all,z_score_var, part_def = 0):\n",
    "    z_matrix=[]\n",
    "    z_matrix_aux=[]\n",
    "    \n",
    "    if part_def==0:\n",
    "        z_matrix = (data_all[z_score_var] - data_all[z_score_var].mean())/ data_all[z_score_var].std()\n",
    "    else:\n",
    "        for i in (data_all[part_def].unique()):\n",
    "            Choicedata = data_all.loc[data_all[part_def] == i]    \n",
    "        \n",
    "            pX_A= pd.to_numeric(Choicedata[z_score_var]) \n",
    "            pX_zA= (pX_A - np.mean(pX_A))/np.std(pX_A)\n",
    "    \n",
    "            z_matrix_aux= pX_zA.values\n",
    "        \n",
    "            for  j in range(len(z_matrix_aux)):    \n",
    "                z_matrix.append(z_matrix_aux[j])\n",
    "    return z_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv('data/DataFoodFramingNotebook_31.csv') \n",
    "# restart number of participants to make it sequencial (for )\n",
    "data_all['Part'] = data_all['Part'].replace(data_all.Part.unique(), list(range(len(data_all.Part.unique()))))\n",
    "# choose only like trials\n",
    "data_part_all =  data_all.loc[data_all.BlockCond == 1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_part_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score values\n",
    "data_part_all['zLValue'] = z_score1(data_part_all,'LValue', 'Part')\n",
    "data_part_all['zRValue'] = z_score1(data_part_all,'RValue', 'Part')\n",
    "data_part_all['zAbsDVal'] = z_score1(data_part_all,'absDV', 'Part')\n",
    "data_part_all['zConf'] = z_score1(data_part_all,'Conf', 'Part')\n",
    "data_part_all['zRT'] = z_score1(data_part_all,'ChoiceRT', 'Part')\n",
    "data_part_all['zTotVal'] = z_score1(data_part_all,'TotVal', 'Part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input for models\n",
    "val_a = data_part_all.zLValue.values\n",
    "val_b = data_part_all.zRValue.values\n",
    "absDVal = data_part_all.zAbsDVal.values\n",
    "totVal = data_part_all.zTotVal.values\n",
    "chosenByPart = data_part_all.ChosenITM.values\n",
    "rtByPart = data_part_all.zRT.values\n",
    "confByPart = data_part_all.zConf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confByPart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtByPart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model GLM: confidence ~rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate graphical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "from matplotlib import rc\n",
    "\n",
    "rc(\"font\", family=\"serif\", size=12)\n",
    "rc(\"text\", usetex=True)\n",
    "\n",
    "# generate nodes for the graphical representation\n",
    "\n",
    "pgm = daft.PGM()\n",
    "\n",
    "s_color = {\"ec\": \"#46a546\"}\n",
    "\n",
    "pgm.add_node(\"sigma\", r\"s\", 5, 2, aspect=2)\n",
    "pgm.add_node(\"intercept\", r\"int\", 3, 2, aspect=2)\n",
    "pgm.add_node(\"x\", r\"x\", 3, 0, aspect=1.2,observed = True)\n",
    "pgm.add_node(\"m\", r\"m\", 3, 1, aspect=1.2)\n",
    "\n",
    "pgm.add_node(\"y\", r\"y\", 5, 0, aspect=1.2,observed = True, plot_params=s_color)\n",
    "\n",
    "# add edges to the graphical model \n",
    "pgm.add_edge(\"sigma\", \"y\", xoffset=-0.1)\n",
    "pgm.add_edge(\"intercept\", \"y\", xoffset=-0.1)\n",
    "pgm.add_edge(\"m\", \"y\", xoffset=-0.1)\n",
    "pgm.add_edge(\"x\", \"y\", xoffset=-0.1)\n",
    "\n",
    "pgm.render(dpi = 200)\n",
    "#pgm.savefig(\"XX.pdf\")\n",
    "#pgm.savefig(\"PEB_BasicModel_2GenVariance_choice_new.png\", dpi=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(pm.HalfCauchy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example: check the priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model00:  # model specifications in PyMC3 are wrapped in a with-statement\n",
    "    # Define priors\n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=10, testval=1.0)\n",
    "    b = pm.Normal(\"b\", 0, sigma=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesPrior = b.random(size=100)\n",
    "plt.hist(samplesPrior, bins=50, histtype=\"stepfilled\")\n",
    "plt.title(\"Prior distribution for b\")\n",
    "#plt.title(\"Prior distribution for $\\sigma$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model00:\n",
    "    a = pm.Normal('a', 50,sigma = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesPriorb = b.random(size=1000)\n",
    "samplesPriora = a.random(size=1000)\n",
    "plt.hist(samplesPriorb, bins=50, histtype=\"stepfilled\")\n",
    "plt.hist(samplesPriora, bins=50, histtype=\"stepfilled\")\n",
    "plt.title(\"Prior distribution selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:  # model specifications in PyMC3 are wrapped in a with-statement\n",
    "    # Define priors\n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=10, testval=1.0)\n",
    "    intercept = pm.Normal(\"Intercept\", 0, sigma=20)\n",
    "    x_coeff = pm.Normal(\"x\", 0, sigma=20)\n",
    "\n",
    "    #likelihood = pm.Normal(\"y\", mu= mu_d, sigma=sigma, observed=confByPart)\n",
    "    \n",
    "    \n",
    "    # Define likelihood\n",
    "    likelihood = pm.Normal(\"y\", mu=intercept + x_coeff * rtByPart, sigma=sigma, observed=confByPart)\n",
    "\n",
    "    # Inference!\n",
    "    start = pm.find_MAP() # use maximum a posteriori as starting point\n",
    "    chains = 5\n",
    "\n",
    "    trace = pm.sample(3000, cores=2,chains = chains, start = start)  # draw 3000 posterior samples using NUTS sampling\n",
    "    burned_trace = trace[1000::2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burned_trace['Intercept']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "pm.traceplot(burned_trace)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.plot_posterior(burned_trace[\"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats_params = az.rhat(burned_trace, method=\"folded\")\n",
    "rhats_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check convergence: rhat<1.05 indicates good convergence\n",
    "\n",
    "Gelman and Rubin (1992) and Brooks and Gelman (1998) suggest that diagnostic Rc values greater than 1.2 for any of the model parameters should indicate nonconvergence. In practice, a more stringent rule of Rc < 1.1 is often used to declare convergence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(burned_trace, round_to=5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plots.autocorrplot(burned_trace, varnames=[\"Intercept\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model estimators (for model selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.waic(burned_trace)\n",
    "waic1 = pm.waic(burned_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.loo(burned_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = pm.sample_posterior_predictive(burned_trace, samples=2000, model=model,var_names = ['x','y','Intercept','sigma'])              #var_names = ['choice]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ppc['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show data vs posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(rtByPart, confByPart, \"x\", label=\"data\")\n",
    "pm.plot_posterior_predictive_glm(burned_trace, samples=100,eval=rtByPart, label=\"posterior predictive regression lines\")\n",
    "#plt.plot(rtByPart, true_regression_line, label=\"true regression line\", lw=3.0, c=\"y\")\n",
    "\n",
    "plt.title(\"Posterior predictive regression lines\")\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel(\"RT\")\n",
    "plt.ylabel(\"Confidence\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using \"simple\" GLM definition in PyMC3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['rt'] =rtByPart\n",
    "df1['conf'] = confByPart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model2:\n",
    "    # specify glm and pass in data. The resulting linear model, its likelihood and\n",
    "    # and all its parameters are automatically added to our model.\n",
    "    pm.glm.GLM.from_formula(\"conf ~ rt \", df1)\n",
    "    step = pm.Metropolis()\n",
    "    trace2 = pm.sample(3000, step =step)  # draw 3000 posterior samples using NUTS sampling\n",
    "    burned_trace2 = trace2[1000::2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(burned_trace2, round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.waic(burned_trace2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic2 = pm.waic(burned_trace2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = pm.sample_posterior_predictive(burned_trace2, samples=50, model=model2,var_names = ['Intercept','rt','Intercept','sd'])              #var_names = ['choice]) \n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(rtByPart, confByPart, \"x\", label=\"data\")\n",
    "#pm.plot_posterior_predictive_glm(trace2, samples=100, label=\"posterior predictive regression lines\")\n",
    "for i in range(len(ppc['rt'])):\n",
    "    plt.plot(rtByPart, ppc['rt'][i]*rtByPart + ppc['Intercept'][i] , label=\"true regression line\", lw=3.0, c=\"y\")\n",
    "\n",
    "plt.title(\"Posterior predictive regression lines\")\n",
    "#plt.legend(loc=0)\n",
    "plt.xlabel(\"RT\")\n",
    "plt.ylabel(\"Confidence\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Simulations/Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = pm.sample_posterior_predictive(burned_trace, samples=2000, model=model,var_names = ['x','Intercept','sigma'])              #var_names = ['choice]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_Inter = ppc['Intercept'].mean()\n",
    "sim_sigma = ppc['sigma'].mean()\n",
    "sim_x = ppc['x'].mean()\n",
    "\n",
    "print('Simulated Inter:' + str(sim_Inter))\n",
    "print('Simulated s:' + str(sim_sigma))\n",
    "print('Simulated x:' + str(sim_x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using same rt than in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:  # model specifications in PyMC3 are wrapped in a with-statement\n",
    "    # Define parameters for the simulation\n",
    "    sigma = sim_sigma\n",
    "    intercept = sim_Inter\n",
    "    x_coeff = sim_x\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = pm.Normal(\"y\", mu=intercept + x_coeff * rtByPart, sigma=sigma, shape = len(rtByPart))\n",
    "\n",
    "    # sample without fixing observed data\n",
    "    trace = pm.sample(500, cores=2)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rtByPart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(rtByPart, trace['y'][0] ,'x' , label=\"sims 1\", alpha = 0.2)\n",
    "plt.plot(rtByPart, trace['y'][1] ,'x' , label=\"sims 2\", alpha = 0.2)\n",
    "plt.plot(rtByPart, trace['y'][2] ,'x' , label=\"sims 3\", alpha = 0.2)\n",
    "\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.title(\"Simulated Data\")\n",
    "plt.xlabel(\"RT\")\n",
    "plt.ylabel(\"Confidence\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating random rt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtSims = np.random.uniform(low=-4, high=6, size=(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rtSims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:  # model specifications in PyMC3 are wrapped in a with-statement\n",
    "    # Define parameters for the simulation\n",
    "    sigma = sim_sigma\n",
    "    intercept = sim_Inter\n",
    "    x_coeff = sim_x\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = pm.Normal(\"y\", mu=intercept + x_coeff * rtSims, sigma=sigma, shape = len(rtSims))\n",
    "\n",
    "    # Inference!\n",
    "    trace = pm.sample(500, cores=2)  # draw 3000 posterior samples using NUTS sampling\n",
    "    #burned_trace = trace[1000::2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(rtSims, trace['y'][0] ,'x' , label=\"sims 1\", alpha = 0.2)\n",
    "plt.plot(rtSims, trace['y'][1] ,'x' , label=\"sims 2\", alpha = 0.2)\n",
    "plt.plot(rtSims, trace['y'][2] ,'x' , label=\"sims 3\", alpha = 0.2)\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.title(\"Simulated Data\")\n",
    "plt.xlabel(\"RT\")\n",
    "plt.ylabel(\"Confidence\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. defining a hierarchical GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_names = data_part_all.Part.unique()\n",
    "part_idx = data_part_all.Part.values\n",
    "part_idx = part_idx.astype(int)\n",
    "n_part = len(data_part_all.Part.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rtByPart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtByPart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(part_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(confByPart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "from matplotlib import rc\n",
    "\n",
    "rc(\"font\", family=\"serif\", size=12)\n",
    "rc(\"text\", usetex=True)\n",
    "\n",
    "# generate nodes for the graphical representation\n",
    "\n",
    "pgm = daft.PGM()\n",
    "\n",
    "s_color = {\"ec\": \"#46a546\"}\n",
    "\n",
    "#pgm.add_node(\"mu_sigma\", r\"$\\mu_s$\", 4.5, 3, aspect=1)\n",
    "#pgm.add_node(\"sd_sigma\", r\"$\\sigma_s$\", 5.3, 3, aspect=1)\n",
    "\n",
    "pgm.add_node(\"mu_intercept\", r\"$\\mu_{int}$\", 3.5, 3, aspect=1)\n",
    "pgm.add_node(\"sd_intercept\", r\"$\\sigma_{int}$\", 2.5, 3, aspect=1)\n",
    "\n",
    "pgm.add_node(\"mu_m\", r\"$\\mu_{m}$\", 2, 2.3, aspect=1)\n",
    "pgm.add_node(\"sd_m\", r\"$\\sigma_{m}$\", 2, 1.7, aspect=1)\n",
    "\n",
    "pgm.add_node(\"m\", r\"m\", 3, 1.7, aspect=1.2)\n",
    "pgm.add_node(\"sigma\", r\"s\", 5, 3, aspect=1)\n",
    "pgm.add_node(\"intercept\", r\"int\", 3, 2.3, aspect=1)\n",
    "pgm.add_node(\"x\", r\"x\", 3, 1, aspect=1.2,observed = True)\n",
    "\n",
    "pgm.add_node(\"y\", r\"y\", 5, 1, aspect=1.2,observed = True, plot_params=s_color)\n",
    "\n",
    "# add edges to the graphical model \n",
    "pgm.add_edge(\"m\", \"y\", xoffset=-0.1)\n",
    "\n",
    "pgm.add_edge('mu_m',\"m\", xoffset=-0.1)\n",
    "pgm.add_edge('sd_m',\"m\", xoffset=-0.1)\n",
    "\n",
    "#pgm.add_edge('mu_sigma',\"sigma\", xoffset=-0.1)\n",
    "#pgm.add_edge('sd_sigma',\"sigma\", xoffset=-0.1)\n",
    "\n",
    "pgm.add_edge('mu_intercept',\"intercept\", xoffset=-0.1)\n",
    "pgm.add_edge('sd_intercept',\"intercept\", xoffset=-0.1)\n",
    "\n",
    "pgm.add_edge(\"sigma\", \"y\", xoffset=-0.1)\n",
    "pgm.add_edge(\"intercept\", \"y\", xoffset=-0.1)\n",
    "pgm.add_edge(\"x\", \"y\", xoffset=-0.1)\n",
    "\n",
    "pgm.add_plate([2.5,0.3, 3, 2.4], label=r\"participants $p$\")\n",
    "\n",
    "pgm.render(dpi = 200)\n",
    "#pgm.savefig(\"XX.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_hier:  # model specifications in PyMC3 are wrapped in a with-statement\n",
    "    \n",
    "    # Define priors fix\n",
    "    mu_intercept = pm.Normal(\"muIntercept\", mu = 0, sigma=100)\n",
    "    sigma_intercept = pm.HalfNormal(\"sigmaIntercept\", 5.0) \n",
    "    \n",
    "    mu_x_coeff = pm.Normal(\"muX\",mu =  0, sigma=100)\n",
    "    sigma_x_coeff = pm.HalfNormal(\"sigmaX\", 5.0) \n",
    "    \n",
    "    # Define priors mix\n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=10, testval=1.0) # noise param \n",
    "    \n",
    "    intercept = pm.Normal(\"Intercept\", mu = mu_intercept, sigma=sigma_intercept, shape = n_part)\n",
    "    x_coeff =   pm.Normal(\"x\", mu = mu_x_coeff, sigma=sigma_x_coeff, shape = n_part)\n",
    "\n",
    "    # Define likelihood\n",
    "    likelihood = pm.Normal(\"y\", mu=intercept[part_idx] + x_coeff[part_idx] * rtByPart, sigma=sigma, observed=confByPart)\n",
    "\n",
    "    # Inference!\n",
    "    trace_hier = pm.sample(3000, cores=2)  # draw 3000 posterior samples using NUTS sampling\n",
    "    burned_trace_hier = trace_hier[1000::2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "pm.traceplot(burned_trace_hier)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhats_params = az.rhat(burned_trace_hier, method=\"folded\")\n",
    "rhats_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check convergence: rhat<1.05 indicates good convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(burned_trace_hier, round_to=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model estimator (for model comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.waic(burned_trace_hier)\n",
    "waic_hier = pm.waic(burned_trace_hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.loo(burned_trace_hier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate samples from the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = pm.sample_posterior_predictive(trace_hier, samples=2000, model=model_hier,var_names = ['x','y','Intercept','sigma'])              #var_names = ['choice]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show relationship data and posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = pm.sample_posterior_predictive(burned_trace2, samples=50, model=model2,var_names = ['Intercept','rt','Intercept','sd'])              #var_names = ['choice]) \n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(rtByPart, confByPart, \"x\", label=\"data\")\n",
    "#pm.plot_posterior_predictive_glm(trace2, samples=100, label=\"posterior predictive regression lines\")\n",
    "for i in range(len(ppc['rt'])):\n",
    "    plt.plot(rtByPart, ppc['rt'][i]*rtByPart + ppc['Intercept'][i] , label=\"true regression line\", lw=3.0, c=\"y\")\n",
    "\n",
    "plt.title(\"Posterior predictive regression lines\")\n",
    "#plt.legend(loc=0)\n",
    "plt.xlabel(\"RT\")\n",
    "plt.ylabel(\"Confidence\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model comparison -- pooled vs hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysize = 20\n",
    "ticksize = 20\n",
    "nticks = 7\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,8))\n",
    "sns.set(style='white', font_scale=1.8)\n",
    "\n",
    "ax.set_facecolor('xkcd:white')\n",
    "width_bars = 0.4\n",
    "bars1 = plt.bar([0,1],[ waic1[0], waic_hier[0]], color='#4F6A9A',width = width_bars, hatch = '')\n",
    "\n",
    "#patterns = ('', '')\n",
    "plt.ylim(-5700,-4000)\n",
    "plt.ylabel('WAIC score',fontsize = ysize )\n",
    "    \n",
    "# Turn off tick labels\n",
    "plt.xticks([0,1],['Pooled','Heuristic'],fontsize = 20)\n",
    "plt.axhline(0, color='black', lw=2, alpha=0.5)\n",
    "plt.yticks(fontsize=ticksize)\n",
    "ax.yaxis.set_major_locator(plt.MaxNLocator(nticks))\n",
    "ax.xaxis.tick_top()\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_loo = az.compare({\"hierarchical\":burned_trace_hier , \"pooled\":burned_trace },ic=\"waic\")\n",
    "az.plot_compare(df_comp_loo, insample_dev=False);\n",
    "df_comp_loo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional model: fit to choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "from matplotlib import rc\n",
    "\n",
    "rc(\"font\", family=\"serif\", size=12)\n",
    "rc(\"text\", usetex=True)\n",
    "\n",
    "# generate nodes for the graphical representation\n",
    "\n",
    "pgm = daft.PGM()\n",
    "\n",
    "s_color = {\"ec\": \"#46a546\"}\n",
    "\n",
    "pgm.add_node(\"lValue\", r\"lValue\", -0.5, 3, aspect=2)\n",
    "pgm.add_node(\"rValue\", r\"rValue\", 3.5, 3, aspect=2)\n",
    "pgm.add_node(\"sigmaGen1\", r\"$\\sigma_{bel,l}$\", 1.5, 4.2, aspect=1.2)\n",
    "#pgm.add_node(\"sigmaGen2\", r\"$\\sigma_{bel,h}$\", 1.8, 4.2, aspect=1.2)\n",
    "pgm.add_node(\"mu1\", r\"$\\mu_{bel,l}$\", 0.6, 3.4, aspect=1.2,observed = True)\n",
    "pgm.add_node(\"mu2\", r\"$\\mu_{bel,h}$\", 2.4, 3.4, aspect=1.2,observed = True)\n",
    "pgm.add_node(\"vl\", r\"$v_l$\", -0.5, 5, aspect=1,observed = True)\n",
    "pgm.add_node(\"vr\", r\"$v_r$\", 3.5, 5, aspect=1,observed = True)\n",
    "pgm.add_node(\"LLR\", r\"LLR\", 1.5, 3, aspect=1.2)\n",
    "pgm.add_node(\"b\", r\"$\\beta$\", 0.5, 2.3, aspect=1)\n",
    "pgm.add_node(\"p\", r\"p\", 1.5, 2, aspect=1)\n",
    "pgm.add_node(\"choice\", r\"choice\", 1.5, 1.2, aspect=2,plot_params=s_color)\n",
    "\n",
    "\n",
    "# add edges to the graphical model \n",
    "pgm.add_edge(\"vl\", \"lValue\", xoffset=-0.1)\n",
    "pgm.add_edge(\"vr\", \"rValue\", xoffset=-0.1)\n",
    "pgm.add_edge(\"mu1\", \"LLR\", xoffset=-0.1)\n",
    "pgm.add_edge(\"mu2\", \"LLR\", xoffset=-0.1)\n",
    "pgm.add_edge(\"sigmaGen1\", \"LLR\", xoffset=-0.1)\n",
    "#pgm.add_edge(\"sigmaGen2\", \"LLR\", xoffset=-0.1)\n",
    "pgm.add_edge(\"rValue\", \"LLR\", xoffset=-0.1)\n",
    "pgm.add_edge(\"lValue\", \"LLR\", xoffset=-0.1)\n",
    "pgm.add_edge(\"LLR\", \"p\", xoffset=-0.1)\n",
    "pgm.add_edge(\"b\", \"p\", xoffset=-0.1)\n",
    "pgm.add_edge(\"p\", \"choice\", xoffset=-0.1)\n",
    "\n",
    "\n",
    "\n",
    "pgm.render()\n",
    "#pgm.savefig(\"XX.pdf\")\n",
    "#pgm.savefig(\"PEB_BasicModel_2GenVariance_choice_new.png\", dpi=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant constant for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_sort = val_a.copy()\n",
    "value_sort.sort()\n",
    "value_low = value_sort[:int(len(value_sort)/2)]\n",
    "value_high = value_sort[int(len(value_sort)/2) + 1 :]\n",
    "\n",
    "plt.title(r\"Distribution of low and high values\")\n",
    "figsize(7, 7)\n",
    "plt.hist(value_low, bins=10, alpha=0.85,\n",
    "             label=r\"Low Value\", color=\"#7A68A6\", normed=True)\n",
    "plt.hist(value_high, bins=10, alpha=0.85,\n",
    "             label=r\"High Value\", color=\"#F47118\", normed=True)\n",
    "plt.legend()\n",
    "\n",
    "print ('mean values -> high: '+ str(value_high.mean()) +' ,  low:'+ str(value_low.mean()))\n",
    "print ('stdev values -> high: '+ str(value_high.std()) +' ,  low:'+ str(value_low.std()))\n",
    "\n",
    "n_trials = len(val_a)\n",
    "mu = [value_low.mean(), value_high.mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_choice1:\n",
    "    # get value for each trial, generate sample for each \n",
    "    sigmaBel = pm.Uniform('sigmaBel', lower=0.5, upper=5) # low value distribution\n",
    "    sigmaSamp = pm.Uniform('sigmaSamp', lower=0.5, upper=5)\n",
    "\n",
    "    lVal = pm.Normal('lVal', mu = val_a, sigma = sigmaSamp , shape = n_trials)\n",
    "    rVal = pm.Normal('rVal', mu = val_b, sigma = sigmaSamp  , shape = n_trials)\n",
    "    \n",
    "    # estimate odds ratio for the choice of right option\n",
    "    \n",
    "    LLR = pm.Deterministic('LLR',  tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(rVal - mu[1] , 2.) / (2 * tt.power(sigmaBel, 2.)))) - \n",
    "                                   tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(rVal - mu[0] , 2.) / (2 * tt.power(sigmaBel, 2.)))) + \n",
    "                                   tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(lVal - mu[0] , 2.) / (2 * tt.power(sigmaBel, 2.)))) -\n",
    "                                   tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(lVal - mu[1] , 2.) / (2 * tt.power(sigmaBel, 2.))))  )\n",
    "\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=0.001, testval = 0)\n",
    "   # alpha = pm.Normal(\"alpha\", mu=0, tau=0.001, testval=0)\n",
    "    p = pm.Deterministic(\"p\", 1.0/(1. + tt.exp(beta*LLR)))    \n",
    "    \n",
    "    choice = pm.Bernoulli(\"choice\", p, observed=chosenByPart)\n",
    "\n",
    "    conf = pm.Deterministic('conf',abs(LLR))   \n",
    "    \n",
    "    #start = pm.find_MAP()\n",
    "    step1 = pm.Metropolis()\n",
    "    \n",
    "    nchains = 4\n",
    "    trace_choice1 = pm.sample(3000, step =step1 ,chains= nchains)\n",
    "    burned_trace_choice1 = trace_choice1[1000::2]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(burned_trace_choice1, round_to=4,var_names=[\"beta\",'sigmaBel','sigmaSamp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(burned_trace_choice1, var_names=[\"beta\",'sigmaBel','sigmaSamp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simHumanBehavPlots (burned_trace_choice1, model_choice1,data_part_all,colorP = ['#4F6A9A','#AFBBD1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.waic(burned_trace_choice1)\n",
    "waic_choice1 = pm.waic(burned_trace_choice1)\n",
    "waic_choice1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_choice2:\n",
    "# get value for each trial, generate sample for each \n",
    "    sigmaBel = pm.Uniform('sigmaBel', lower=0.5, upper=5) # low value distribution\n",
    "    sigmaSamp = pm.Uniform('sigmaSamp', lower=0.5, upper=5)\n",
    "    \n",
    "    lVal = pm.Normal('lVal', mu = val_a, sigma = sigmaSamp , shape = n_trials)\n",
    "    rVal = pm.Normal('rVal', mu = val_b, sigma = sigmaSamp  , shape = n_trials)\n",
    "    \n",
    "    # estimate odds ratio for the choice of right option\n",
    "    \n",
    "    LLR = pm.Deterministic('LLR',  tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(rVal - mu[1] , 2.) / (2 * tt.power(sigmaBel, 2.)))) - \n",
    "                                   tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(rVal - mu[0] , 2.) / (2 * tt.power(sigmaBel, 2.)))) + \n",
    "                                   tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(lVal - mu[0] , 2.) / (2 * tt.power(sigmaBel, 2.)))) -\n",
    "                                   tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(lVal - mu[1] , 2.) / (2 * tt.power(sigmaBel, 2.))))  )\n",
    "\n",
    "    beta = pm.Normal(\"beta\", mu=0, tau=0.001, testval=0)\n",
    "    p = pm.Deterministic(\"p\", 1.0/(1. + tt.exp(beta*LLR) ))    \n",
    "    \n",
    "    choice = pm.Bernoulli(\"choice\", p, observed=chosenByPart)\n",
    "\n",
    "    start = pm.find_MAP()\n",
    "    step = pm.Metropolis()\n",
    "    nchains = 4\n",
    "    trace_choice2 = pm.sample(3000, step =step ,chains= nchains)\n",
    "    burned_trace_choice2 = trace_choice2[1000::2]    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(burned_trace_choice2, round_to=4,var_names=[\"beta\",'sigmaBel','sigmaSamp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(burned_trace_choice2, var_names=[\"beta\",'sigmaBel','sigmaSamp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simHumanBehavPlots (burned_trace_choice2, model_choice2,data_part_all,colorP = ['#4F6A9A','#AFBBD1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.waic(burned_trace_choice2)\n",
    "waic_choice2 = pm.waic(burned_trace_choice2)\n",
    "waic_choice2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = pm.sample_posterior_predictive(burned_trace_choice2, samples = 2000, model = model_choice2,var_names = ['sigmaBel','sigmaSamp','beta'])              #var_names = ['choice]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmaBel_fit_mean = ppc['sigmaBel'].mean()  \n",
    "sigmaSamp_fit_mean = ppc['sigmaSamp'].mean()  \n",
    "beta_fit_mean = ppc['beta'].mean()  \n",
    "\n",
    "sigmaBel_fit_sd = ppc['sigmaBel'].std()  \n",
    "sigmaSamp_fit_sd = ppc['sigmaSamp'].std()  \n",
    "beta_fit_sd = ppc['beta'].std()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_fit_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_fit_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_sims:\n",
    "# get value for each trial, generate sample for each \n",
    "    sigmaBel =  pm.Normal(\"sigmaBel\", mu=sigmaBel_fit_mean, sigma=sigmaBel_fit_sd)\n",
    "    sigmaSamp =  pm.Normal(\"sigmaSamp\", mu=sigmaSamp_fit_mean, sigma=sigmaSamp_fit_sd)\n",
    "    \n",
    "    lVal = pm.Normal('lVal', mu = val_a, sigma = sigmaSamp , shape = n_trials)\n",
    "    rVal = pm.Normal('rVal', mu = val_b, sigma = sigmaSamp  , shape = n_trials)\n",
    "    \n",
    "    # estimate odds ratio for the choice of right option\n",
    "    \n",
    "    LLR = pm.Deterministic('LLR',  tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(rVal - mu[1] , 2.) / (2 * tt.power(sigmaBel, 2.)))) - \n",
    "                                   tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(rVal - mu[0] , 2.) / (2 * tt.power(sigmaBel, 2.)))) + \n",
    "                                   tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(lVal - mu[0] , 2.) / (2 * tt.power(sigmaBel, 2.)))) -\n",
    "                                   tt.log(1/(sigmaBel * tt.sqrt(2 * np.pi))*tt.exp(-tt.power(lVal - mu[1] , 2.) / (2 * tt.power(sigmaBel, 2.))))  )\n",
    "\n",
    "    beta =     pm.Normal(\"beta\", mu=beta_fit_mean, sigma=beta_fit_sd)\n",
    "    p = pm.Deterministic(\"p\", 1.0/(1. + tt.exp(beta*LLR) ))    \n",
    "    \n",
    "    choice = pm.Bernoulli(\"choice\", p, shape = n_trials)\n",
    "\n",
    "    #start = pm.find_MAP()\n",
    "    step = pm.Metropolis()\n",
    "    #nchains = 4\n",
    "    trace_choice_sims = pm.sample(1000, step = step)\n",
    "    #burned_trace_choice2 = trace_choice2[1000::2]    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simHumanBehavPlots (trace_choice_sims, model_sims,data_part_all,colorP = ['#4F6A9A','#AFBBD1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = pm.sample_posterior_predictive(trace_choice_sims, samples = 10, model = model_sims,var_names = ['p','choice'])              #var_names = ['choice]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc['choice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_b - val_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = pm.sample_posterior_predictive(trace_choice_sims, samples=10, model=model_sims,var_names = ['choice']) # generates samples from the posterior, im this case the samples consider the 120 trials inputs\n",
    "\n",
    "posterior_df = pd.DataFrame()\n",
    "posterior_df['choice'] = ppc['choice'].flatten()\n",
    "posterior_df['lValue'] = np.tile(val_a, len(ppc['choice']))\n",
    "posterior_df['rValue'] = np.tile(val_b, len(ppc['choice']))\n",
    "posterior_df['dValue'] = np.tile(val_b - val_a, len(ppc['choice']))\n",
    "posterior_df['sumValue'] = np.tile(val_b + val_a, len(ppc['choice']))\n",
    "posterior_df['absDValue'] = np.tile(np.abs(val_b - val_a), len(ppc['choice']))\n",
    "RbiggerL = np.tile((val_b>val_a), len(ppc['choice']))\n",
    "posterior_df['correct'] = RbiggerL == posterior_df['choice']\n",
    "\n",
    "\n",
    "## FIGURE\n",
    "logisticplot_simpl ('Simulations', posterior_df, xaxis='dValue', yaxis='choice', ylab='P(Chose Right Item)', xlab='$\\Delta$Value',\n",
    "                  modlowcol='#000000', title='empty',xlim = [-5,5])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "    # FIGURE\n",
    "posterior_df['correct'].value_counts(normalize=1,sort=0).plot(kind='bar',title='Accuracy')\n",
    "plt.ylabel('proportion')\n",
    "plt.show()\n",
    "\n",
    "posterior_df['choice'].value_counts(normalize=1,sort=0).plot(kind='bar',title='Choice right')\n",
    "plt.ylabel('frquency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix - extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simHumanBehavPlots (burned_trace, model_peb1,data_part_all_test,colorP = ['#4F6A9A','#AFBBD1']):\n",
    "\n",
    "    ppc = pm.sample_posterior_predictive(burned_trace, samples=50, model=model_peb1,var_names = ['choice']) # generates samples from the posterior, im this case the samples consider the 120 trials inputs\n",
    "\n",
    "    posterior_df = pd.DataFrame()\n",
    "    posterior_df['choice'] = ppc['choice'].flatten()\n",
    "    posterior_df['lValue'] = np.tile(val_a, len(ppc['choice']))\n",
    "    posterior_df['rValue'] = np.tile(val_b, len(ppc['choice']))\n",
    "    posterior_df['dValue'] = np.tile(val_b - val_a, len(ppc['choice']))\n",
    "    posterior_df['sumValue'] = np.tile(val_b + val_a, len(ppc['choice']))\n",
    "    posterior_df['absDValue'] = np.tile(np.abs(val_b - val_a), len(ppc['choice']))\n",
    "    RbiggerL = np.tile((val_b>val_a), len(ppc['choice']))\n",
    "    posterior_df['correct'] = RbiggerL == posterior_df['choice']\n",
    "    \n",
    "    data_part = pd.DataFrame()    \n",
    "    data_part['choice'] = data_part_all_test.ChosenITM\n",
    "    data_part['dValue'] = data_part_all_test.zRValue - data_part_all_test.zLValue \n",
    "    # z-score participant\n",
    "    data_part['zAbsDValue'] =  data_part_all_test.zAbsDV.values\n",
    "    data_part['zSumValue'] = data_part_all_test.zTotVal.values\n",
    "    # add chosen and unchosen\n",
    "    data_part['Part'] = data_part_all_test.Part\n",
    "    \n",
    "    ## FIGURE\n",
    "    logisticplot_simpl ('Simulations', posterior_df, xaxis='dValue', yaxis='choice', ylab='P(Chose Right Item)', xlab='$\\Delta$Value',\n",
    "                      modlowcol='#000000', title='empty',xlim = [-5,5])\n",
    "    \n",
    "    logisticplot_simplDots ('Human', data_part, xaxis='dValue', yaxis='choice', ylab='P(Chose Right Item)', xlab='$\\Delta$Value',\n",
    "                            meanCol=colorP[0], subjCol = colorP[1], title='empty',xlim = [-5,5])\n",
    "    \n",
    "    logisticplot_simpl ('', data_part, xaxis='dValue', yaxis='choice', ylab='P(Chose Right Item)', xlab='$\\Delta$Value',\n",
    "                      modlowcol=colorP[0], title='empty', linewidth = 3 ,xlim = [-5,5])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "        # FIGURE\n",
    "    posterior_df['correct'].value_counts(normalize=1,sort=0).plot(kind='bar',title='Accuracy')\n",
    "    plt.ylabel('proportion')\n",
    "    plt.show()\n",
    "    \n",
    "    posterior_df['choice'].value_counts(normalize=1,sort=0).plot(kind='bar',title='Choice right')\n",
    "    plt.ylabel('frquency')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_simpl (modlow, data, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',\n",
    "                  modlowcol='#AAAAAA', title='empty', xlim = [-5,5],linewidth = 5):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    figsize(5,5)\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "\n",
    "    #run the classifier\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    logit_low = {}\n",
    "\n",
    "    # I think this defines the problem space\n",
    "    X_test = np.linspace(-10,10,300)\n",
    "\n",
    "    # fitting the predictive logistic model for the low_confidence trials, for a participant specified by x\n",
    "    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data[xaxis][:, np.newaxis],\n",
    "            data [yaxis])\n",
    "    logit_low = model(X_test*clf.coef_ + clf.intercept_).ravel()\n",
    "    print ('Slope Coef',clf.coef_)\n",
    "    \n",
    "    #Plotting the predictive lines\n",
    "    line_low = sub.plot(X_test, logit_low, color=modlowcol, linewidth=5, label=modlow, zorder=5) \n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=30)\n",
    "    sub.set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "    # Set Ticks\n",
    "    sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "    sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "    sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "    sub.set_ylim(-0.01, 1.01)\n",
    "    sub.set_xlim(xlim[0], xlim[1])\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    sub.legend(frameon=False, prop={'size':20})\n",
    "    \n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_simplDots (modlow, data, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',\n",
    "                  meanCol='#AAAAAA',subjCol='#000000', title='empty', xlim = [-5,5]):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    figsize(5,5)\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "\n",
    "    #run the classifier\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    logit_low = {}\n",
    "\n",
    "    # I think this defines the problem space\n",
    "    X_test = np.linspace(-10,10,300)\n",
    "\n",
    "    # fitting the predictive logistic model for the low_confidence trials, for a participant specified by x\n",
    "    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data[xaxis][:, np.newaxis],\n",
    "            data [yaxis])\n",
    "    logit_low = model(X_test*clf.coef_ + clf.intercept_).ravel()\n",
    "    print ('Slope coef',clf.coef_)\n",
    "    \n",
    "    #      data.groupby(['Part', 'difficulty']).choice.mean()\n",
    "\n",
    "    \n",
    "    # generate scatter to plot pariticipants means\n",
    "    \n",
    "    levels =  (np.max(data[xaxis]) - np.min(data[xaxis]))/10\n",
    "    lev_label = np.arange(np.min(data[xaxis]), np.max(data[xaxis]) + levels,levels) \n",
    "    \n",
    "    difficulty2= []\n",
    "    for i in range(len(data[xaxis].values)):\n",
    "         difficulty2.append( lev_label[ int((data[xaxis].values[i] - np.min(data[xaxis]) )//levels)] )\n",
    "            \n",
    "    data['difficulty'] = np.around(difficulty2, decimals = 3)        \n",
    "    \n",
    "    subject_means = data.groupby(['Part', 'difficulty']).choice.mean()\n",
    "    means = subject_means.groupby('difficulty').mean()\n",
    "    sems = subject_means.groupby('difficulty').sem()\n",
    "    \n",
    "    #Plotting the predictive lines\n",
    "    #line_low = sub.scatter(X_test, logit_low, color=modlowcol, linewidth=5, label=modlow, zorder=5) \n",
    "\n",
    "    # plot subject means\n",
    "    scatter_data = subject_means.reset_index()\n",
    "    x_scatter = scatter_data['difficulty'] \n",
    "    jittr = np.random.uniform(low=-max(x_scatter)/10,high=max(x_scatter)/10,size=len(scatter_data))/2\n",
    "    sub.plot(x_scatter+jittr, scatter_data.choice.values, marker='o', ms=5, markerfacecolor=subjCol, color=subjCol,alpha=0.3,linestyle=\"None\")\n",
    "\n",
    "    # plot mean values\n",
    "    sub.plot(list(means.index), means.values, 'o', markerfacecolor=meanCol, markersize = 10, fillstyle = 'full',\n",
    "                    color=meanCol, linewidth=1,label=modlow)\n",
    "    sub.vlines(list(means.index), means - sems, means + sems,\n",
    "                      linewidth=1, color= meanCol)\n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=30)\n",
    "    sub.set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "    # Set Ticks\n",
    "    #sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "    sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "    sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "    sub.set_ylim(-0.01, 1.01)\n",
    "    sub.set_xlim(xlim[0], xlim[1])\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    sub.legend(frameon=False, prop={'size':20})\n",
    "    \n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------- END --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
